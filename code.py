# -*- coding: utf-8 -*-
"""MIC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t4jLtijLeUrqzt9L876_ALcR6dtjDI8g
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

#  Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import joblib

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Load dataset
file_path = "/content/drive/MyDrive/MIC rec/IMDB_Dataset.csv"  # adjust if filename is different
df = pd.read_csv(file_path)

print("Dataset shape:", df.shape)
print(df.head())

# Features and target
X = df["review"]
y = df["sentiment"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Vectorization (TF-IDF)
vectorizer = TfidfVectorizer(stop_words="english", max_features=10000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Define models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)
}

results = []

# Train & evaluate models
for name, model in models.items():
    model.fit(X_train_vec, y_train)
    y_pred = model.predict(X_test_vec)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average="weighted")
    rec = recall_score(y_test, y_pred, average="weighted")
    f1 = f1_score(y_test, y_pred, average="weighted")
     # Training performance
    y_train_pred = model.predict(X_train_vec)
    train_acc = accuracy_score(y_train, y_train_pred)
    train_prec = precision_score(y_train, y_train_pred, average="weighted")
    train_rec = recall_score(y_train, y_train_pred, average="weighted")
    train_f1 = f1_score(y_train, y_train_pred, average="weighted")

    # Plot training vs test performance
    metrics = ["Accuracy", "Precision", "Recall", "F1-score"]
    train_scores = [train_acc, train_prec, train_rec, train_f1]
    test_scores = [acc, prec, rec, f1]

    x = range(len(metrics))
    plt.figure(figsize=(6,4))
    plt.bar(x, train_scores, width=0.4, label="Train", align="center")
    plt.bar([i + 0.4 for i in x], test_scores, width=0.4, label="Test", align="center")
    plt.xticks([i + 0.2 for i in x], metrics)
    plt.ylim(0,1)
    plt.title(f"Train vs Test Performance - {name}")
    plt.legend()
    plt.show()


    results.append([name, acc, prec, rec, f1])

    # Confusion Matrix
    ConfusionMatrixDisplay.from_estimator(model, X_test_vec, y_test, cmap="Blues")
    plt.title(f"Confusion Matrix - {name}")
    plt.show()

    # Save model as pkl file to Drive
    save_path = f"/content/drive/MyDrive/{name.replace(' ', '_')}.pkl"
    joblib.dump(model, save_path)
    print(f"✅ {name} saved to {save_path}")

#Compare results in DataFrame
import pandas as pd
results_df = pd.DataFrame(results, columns=["Model", "Accuracy", "Precision", "Recall", "F1-score"])
print("\nModel Comparison:\n", results_df)

#  Visualization of metrics
results_df.set_index("Model")[["Accuracy","Precision","Recall","F1-score"]].plot(kind="bar", figsize=(8,5))
plt.title("Model Comparison")
plt.ylabel("Score")
plt.ylim(0,1)
plt.show()

# Save the vectorizer as well (needed for inference later)
joblib.dump(vectorizer, "/content/drive/MyDrive/tfidf_vectorizer.pkl")
print("✅ Vectorizer saved to /content/drive/MyDrive/tfidf_vectorizer.pkl")

ConfusionMatrixDisplay.from_estimator(models["Random Forest"], X_test_vec, y_test, cmap="Blues")
plt.title("Confusion Matrix - Random Forest")
plt.savefig("/content/drive/MyDrive/confusion_matrix_rf.png")
plt.close()